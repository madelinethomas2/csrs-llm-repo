{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "## prompt to answer questions about the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "OPEN_API_KEY = \"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\"\n",
    "os.environ[\"OPEN_API_KEY\"] = OPEN_API_KEY\n",
    "\n",
    "split_docs = []\n",
    "split_docs2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "table_prompt_initial = \"\"\"\n",
    "\\n\\n\n",
    "<TABLE START>:\n",
    "{table}\n",
    "<TABLE END>:\n",
    "\n",
    "The above text between \"<TABLE START>\" and \"<TABLE END>\" is a table formatted in plain language. It contains rows and columns and some rows may have more columns than others. Each row starts with \"RX:\" where \"X\" is the row number, starting at 0. Each column in each row starts with \"CY:\" where \"Y\" is the column number, starting at 0, followed by the text contained in the column, which is surrounded by quotation marks.\\n\\n\n",
    "\"\"\"\n",
    "def process_table(soup_table):\n",
    "    \"\"\"\n",
    "    Function to convert an HTML table to a 2D Python list\n",
    "    :param soup_table: The BeautifulSoup table element\n",
    "    :return: A 2D Python list containing the tabular data\n",
    "    \"\"\"\n",
    "    # This will contain our Table data\n",
    "    data = []\n",
    "\n",
    "    # See if this table has a header, and if so, add it to our data as the first row\n",
    "    header = soup_table.find('thead')\n",
    "    # grab all the headers, extract and clean the text, and add it to our data\n",
    "    if header is not None:\n",
    "        data.append([h.text.strip().replace('\\xa0', ' ') for h in header.find_all('th')])\n",
    "\n",
    "    # grab the main table body\n",
    "    tbody = soup_table.find('tbody')\n",
    "    if tbody is None:\n",
    "        tbody = soup_table\n",
    "\n",
    "    # get all rows\n",
    "    rows = tbody.find_all('tr')\n",
    "\n",
    "    # loop through every row\n",
    "    for row in rows:\n",
    "        # this will hold the data for this column\n",
    "        col_data = []\n",
    "        # check if there is a header, and if so, add it to the column data\n",
    "        header = row.find('th')\n",
    "        if header is not None:\n",
    "            col_data.append(header.text.strip().replace('\\xa0', ' '))\n",
    "\n",
    "        # get al of the data columns for this row\n",
    "        cols = row.find_all('td')\n",
    "\n",
    "        # loop through each element in the column, clean it, and append to col_data\n",
    "        for element in cols:\n",
    "            element = element.text.strip()\n",
    "            if element is None:\n",
    "                col_data.append(\"N/A\")\n",
    "            else:\n",
    "                element = element.replace('\\xa0', ' ')\n",
    "                col_data.append(element)\n",
    "        # add the row to our data\n",
    "        data.append(col_data)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table2text(table):\n",
    "    \"\"\"\n",
    "    This function formats a table into a more human-readable format\n",
    "    :param table: The table loaded from html, a 2D Python list\n",
    "    :return: Formatted string\n",
    "    \"\"\"\n",
    "    table_str = \"\"\n",
    "    # loop through every row\n",
    "    for i, row in enumerate(table):\n",
    "        # indicate which row we are in\n",
    "        table_str += \"R{}: \".format(i)\n",
    "        # loop through every column\n",
    "        for j, column in enumerate(row):\n",
    "            # indicate which column we are in\n",
    "            table_str += 'C{}: \"{}\" '.format(j, column)\n",
    "        # let's add a newline after the last column (probably not necessary)\n",
    "        if i != len(table) - 1:\n",
    "            table_str += '\\n'\n",
    "    return table_prompt_initial.format(table=table_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Import some stuff\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# This list contains all of the HTML tags that contain text that we want to extract\n",
    "# This excludes things like list items and tables, which are handled independently\n",
    "text_containing_tags = [\n",
    "    'p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'strong', 'em',\n",
    "    'blockquote', 'q', 'cite', 'abbr', 'code', 'pre', 'kbd', 'samp', 'var',\n",
    "    'dfn', 'mark', 'ins', 'del', 'time', 'sub', 'sup'\n",
    "]\n",
    "\n",
    "def in_table(element):\n",
    "    \"\"\"\n",
    "    Check if the current element is contained in a t\n",
    "    \n",
    "    able, in which case, it has already beeen processed\n",
    "    :param element: Soup element\n",
    "    :return: True if in table, False otherwise\n",
    "    \"\"\"\n",
    "    # Loop through parent elements\n",
    "    while element:\n",
    "        if element.name in ['table',]:\n",
    "            return True\n",
    "        element = element.parent\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_element(element, text: str = \"\", verbose: bool = False):\n",
    "    \"\"\"\n",
    "    Recursive function that iterates over all elements in the Soup HTML structure and extracts and formats text as prescribed for each type of HTML structure.\n",
    "\n",
    "    NOTE: This function needs to be optimized.\n",
    "\n",
    "    :param element: The soup element (typically the top-level element)\n",
    "    :param text: The string that the function appends the results to\n",
    "    :param verbose: True for verbosity, False otherwise\n",
    "    :return: The extracted text as a String\n",
    "    \"\"\"\n",
    "    # check if element has the name attribute. If it doesn't, it is a nonstandard tag that we want to ignore\n",
    "    if element.name:\n",
    "        # handle tables independently\n",
    "        if element.name == 'table':\n",
    "            if verbose:\n",
    "                print(\"Handling table...\")\n",
    "            table_data = table2text(process_table(element))       \n",
    "            text += table_data\n",
    "            \n",
    "        # handle plain text tags\n",
    "        elif element.name in text_containing_tags:\n",
    "            # check if this was in a table and thus already processed\n",
    "            if not in_table(element):\n",
    "                if verbose:\n",
    "                    print(\"Handling text...\")\n",
    "                element_text = element.get_text()\n",
    "                # ignore any text that is one character or less\n",
    "                if len(element_text) > 1:\n",
    "                    if element.name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:\n",
    "                        text += '\\n\\n'\n",
    "                    # replace consecutive whitespace with a single space\n",
    "                    text += re.sub(r'\\s+', ' ', element_text)\n",
    "                    text += ' '\n",
    "                    text += '\\n'\n",
    "        # if we encountered a list item, then add in the list text (-, bullet point, etc.)\n",
    "        elif element.name == 'li':\n",
    "            if 'data-list-text' in element.attrs:\n",
    "                text += element.attrs['data-list-text']\n",
    "        # ignore table elements because they are already handled in the table handler\n",
    "        elif element.name in ['td', 'tr']:\n",
    "            pass\n",
    "        # ignore the rest\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"Tag type not considered in loop: \" + element.name)\n",
    "    # recursively loop through the children of every element\n",
    "    for child in element.find_all(recursive=False):\n",
    "        text = process_element(child, text, verbose=verbose)\n",
    "    if verbose:\n",
    "        print(\"Done.\")\n",
    "\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Generalized function to process any html file\n",
    "def process_html(html_file: str) -> str:\n",
    "    # open the file\n",
    "    with open(html_file, 'r', encoding='utf-8') as f:\n",
    "        html_text = f.read()\n",
    "    # Parse using BeautifulSoup\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    # Write the prettified HTML to a file so that we can look at it\n",
    "    with open(\"pretty_%s\" % html_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(soup.prettify())\n",
    "        \n",
    "    # format our document\n",
    "    formatted_document = process_element(soup.find('body'), \"\", verbose=False)\n",
    "    # write the results to a text file\n",
    "    with open('formatted_%s.txt' % html_file[:-4], 'w', encoding='utf-8') as f:\n",
    "        f.write(formatted_document)\n",
    "        \n",
    "    return formatted_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Generalized function to create list of split LangChain Document objects\n",
    "def langchain_doc_splitter(formatted_document: str, overlap_percent: int=10) -> list:\n",
    "    doc = Document(page_content=formatted_document)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=60000, chunk_overlap=60000*10/100)\n",
    "    split_docs = text_splitter.split_documents([doc])\n",
    "    \n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's run each section of our double-RAG in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pipe\n",
    "from multiprocessing import Process\n",
    "\n",
    "# create function that runs above functions while providing connections to and from a multiprocessing Pipe\n",
    "def data_preprocessor_pipeline(conn, html_file: str) -> None:\n",
    "    # Get formatted data\n",
    "    formatted_document = process_html(html_file)\n",
    "    # Get split langchain document objects from formatted data\n",
    "    split_docs = langchain_doc_splitter(formatted_document)\n",
    "    # Send split document objects to the pipe\n",
    "    conn.send(split_docs)\n",
    "    conn.close()\n",
    "\n",
    "# IMPORTANT TO-DO: add security authentication for recv/send methods\n",
    "# IMPORTANT TO-DO: following code should be in an \"if __name__ == '__main__':\" block\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Run the data preprocessing pipeline for the requirements html\n",
    "    requirements_recv_conn, requirements_send_conn = Pipe()\n",
    "    requirements_proc = Process(target=data_preprocessor_pipeline, args=(requirements_send_conn, 'RCIP2.html',))\n",
    "    requirements_proc.start()\n",
    "\n",
    "    # Run the data preprocessing pipeline for the proposal html\n",
    "    proposal_recv_conn, proposal_send_conn = Pipe()\n",
    "    proposal_proc = Process(target=data_preprocessor_pipeline, args=(proposal_send_conn, 'proposal.html',))\n",
    "    proposal_proc.start()\n",
    "\n",
    "    # Grab split documents output\n",
    "    split_docs = requirements_recv_conn.recv()\n",
    "    split_docs2 = proposal_recv_conn.recv()\n",
    "\n",
    "    # Join the processes (memory cleaning)\n",
    "    requirements_proc.join()\n",
    "    proposal_proc.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.schema.document.Document"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_docs)\n",
    "type(split_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Let's use an OpenAI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"gpt-3.5-turbo-16k\"  # ChatGPT\n",
    "llm = ChatOpenAI(openai_api_key=OPEN_API_KEY, model_name=model_name, request_timeout=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Refine Summarization Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "initial_template = \"\"\"\n",
    "I am writing a grant proposal and I would like to compare my proposal against the requirements set forth in the below text, nested between <TEXT> tags. Generate a comprehensive and specific overview of those requirements that will help me check my proposal. Your outline must be taken directly from the above text nested between the <TEXT> tags. If tabular data is important, include that too. If the provided information is insufficient to generate the outline, then do not do anything.\n",
    "<TEXT>\n",
    "{text}\n",
    "<TEXT>\n",
    "YOUR RESPONSE:\"\"\"\n",
    "initial_prompt = PromptTemplate.from_template(initial_template)\n",
    "\n",
    "refine_template = \"\"\"\n",
    "<TEXT>\n",
    "{text}\n",
    "<TEXT>\n",
    "I am writing a grant proposal and I would like to compare my proposal against the requirements set forth in the below text, nested between <TEXT> tags. Generate a comprehensive and specific outline of the important requirements that will help me check my proposal for compliance against these requirements by refining the following text nested between <CURRENT OUTLINE> tags, which is an incomplete outline that you generated by processing portions of the grant requirements document. New information used to refine the incomplete outline must be taken directly from the above text nested between the <TEXT> tags. If tabular data is important, include that too. If the provided information is insufficient to refine the outline, then do not modify it.\n",
    "<CURRENT OUTLINE>\n",
    "{existing_answer}\n",
    "<CURRENT OUTLINE>\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "refine_prompt = PromptTemplate.from_template(refine_template)\n",
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",\n",
    "    question_prompt=initial_prompt,\n",
    "    refine_prompt=refine_prompt,\n",
    "    return_intermediate_steps=True,\n",
    "    input_key=\"text\",\n",
    "    output_key=\"output_text\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Generate Requirements Context from RCIP Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I. Program Overview\n",
      "- Resilient Communities Infrastructure Program (RCIP)\n",
      "- Objective of allocating CDBG-DR funds to address unmet needs from 2020-2021 disasters\n",
      "\n",
      "II. Award Determination\n",
      "- Allocation of $100 million from the total $2.3 billion appropriation to fund RCIP projects\n",
      "- Minimum grant award of $600,000\n",
      "- Maximum grant award of $25 million\n",
      "- Funds allocated to various subrecipients based on HUD MID areas\n",
      "\n",
      "III. Program Implementation\n",
      "- Cooperative Endeavor Agreement (CEA) for fund transfer and compliance with laws\n",
      "- Recovery Proposal submission and approval\n",
      "- Separate application form for each project proposed by the recipient\n",
      "- Deadline for submission of Recovery Proposal is 3 months from CEA execution\n",
      "\n",
      "IV. Program Requirements\n",
      "- Subrecipient selection and capacity assessment\n",
      "- Compliance with CDBG National Objective and LMI criteria\n",
      "- Staff capacity for financial management and oversight\n",
      "- Knowledge of federal and state procurement and contracting requirements\n",
      "- Compliance with federal regulations outside of CDBG requirements\n",
      "- Citizen participation requirements and public meetings\n",
      "- Submission requirements for Recovery Proposal and project applications\n",
      "- Timelines for Recovery Proposal, Project Application, and project-specific activities\n",
      "- Changes to projects documented through amendments\n",
      "- Project requests for payment and reporting requirements\n",
      "- Project monitoring and closeout process\n",
      "\n",
      "V. Program Policies and Requirements\n",
      "- Procurement of professional services adhering to policies and procedures\n",
      "- Limitations on project delivery costs\n",
      "- Procedures for determining funds available for reallocation and excess funds\n",
      "- Recapture of funds for non-compliance or ineligible expenditures\n",
      "- Cancellation of projects for various reasons\n",
      "- Unresponsive subrecipients and cancellation process\n",
      "\n",
      "VI. Program Income and Resilience Performance Standards\n",
      "- Compliance with program income requirements\n",
      "- Promotion of high quality, durable, sustainable, and mold resistant construction methods\n",
      "- Elevation and construction standards for floodplain areas\n",
      "- Eligible activities under CDBG-DR funds and additional eligibility requirements\n",
      "\n",
      "VII. Reallocation of Funds and Excess Funds\n",
      "- Reallocation priorities for funds likely to be expended within the HUD expenditure deadline\n",
      "- Determination of excess funds and notification to subrecipients\n",
      "\n",
      "VIII. Recaputure of Funds and Canceling a Project\n",
      "- Recapture of funds for non-compliance or ineligible expenditures\n",
      "- Cancellation of projects for various reasons, such as lack of feasibility or support\n"
     ]
    }
   ],
   "source": [
    "result = chain({\"text\": split_docs}, return_only_outputs=True)\n",
    "outline = result[\"output_text\"]\n",
    "print(outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outline = Document(page_content=outline)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=60000, chunk_overlap=60000*10/100)\n",
    "split_outline = text_splitter.split_documents([outline])\n",
    "len(split_outline)\n",
    "##SPLIT_OUTLINE IS THE RCIP REQUIREMENTS GENERATED BY THE 1ST RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Identify Information from the Proposal related to the requirements context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-3.5-turbo-16k\"  # ChatGPT\n",
    "llm2 = ChatOpenAI(openai_api_key=OPEN_API_KEY, model_name=model_name, request_timeout=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "template = \"\"\"\n",
    "<TEXT>\n",
    "{text}\n",
    "<TEXT>\n",
    "\n",
    "<CONTEXT>\n",
    "{input_documents}\n",
    "<CONTEXT>\n",
    "\n",
    "I am writing a grant proposal and I would like to compare my proposal document, which is nested between <TEXT> tags, against a set of requirements, which is nested between <CONTEXT> tags. I need to ensure that the content in the proposal meets the requirements. Go through each section of the proposal document, including sections A, B, C, D, E, F, G, H, and I, and tell me if each section meets the requirements. Describe why or why not each section meets the requirements. Specifically, first print the original section, then give your description of why or why not this section meets the requirements. If there are requirements that are not touched on in the proposal document, make note of that at the end of your output. If tabular data in the proposal document is important, check that against the requirements too. If the provided information is insufficient to generate an annotation of the proposal, then do not do it.\"\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = load_summarize_chain(\n",
    "    llm=llm2,\n",
    "    chain_type=\"refine\",\n",
    "    question_prompt=prompt,\n",
    "    return_intermediate_steps=True,\n",
    "    output_key=\"output_text\",\n",
    "    input_key= \"text\",\n",
    ")\n",
    "    #input_key=\"input_documents\",\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=120.0).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section A: Project Name and Address\n",
      "Sewerage Lift Station L-14-6 Upgrade at Normandy and Alsace\n",
      "Located at Normandy Ct. and Alsace Ct. in Marrero, Jefferson Parish, Louisiana\n",
      "\n",
      "This section meets the requirements as it provides the project name and address as requested.\n",
      "\n",
      "Section B: Description of the Proposed Project\n",
      "The existing lift station will be replaced with a new lift station, including excavation, installation of a concrete foundation, a new wet well, valve pit, pumps, valves, piping, controls, and other new equipment and related appurtenances. The new design includes wet wells with sloped bottoms and inlets to prevent clogged suction lines and pumps. A SCADA system will also be installed, along with a quick connect isolation junction box for emergency power during outages.\n",
      "\n",
      "This section meets the requirements as it provides a detailed description of the specific project activities and construction to be undertaken.\n",
      "\n",
      "Section C: Estimated Total Project Cost, Source, Status, and Use of Funds\n",
      "- CDBG: $1,000,000 for construction\n",
      "- Local Funds: $270,000 from Jefferson Parish Sewer Funds for program management, engineering, grant management, inspection, surveying, geotechnical, testing lab, and bidding\n",
      "\n",
      "This section meets the requirements as it provides the estimated total project cost, funding sources, status, and use of funds in a table format as requested.\n",
      "\n",
      "Section D: Project Context\n",
      "This project is a separate project that is not dependent upon other projects and will not impact any existing infrastructure.\n",
      "\n",
      "This section meets the requirements as it describes the project context and addresses the questions asked.\n",
      "\n",
      "Section E: Beneficiaries/Public Benefit/Target Area and Boundaries\n",
      "The project will serve a disadvantaged community in Marrero, Jefferson Parish, that was economically distressed prior to the storm events. The beneficiary area includes low- to moderate-income individuals and has a high minority concentration. The project will meet the national objective of area benefit to low/moderate-income residents. The specific project boundaries are provided.\n",
      "\n",
      "This section meets the requirements as it identifies the beneficiaries, describes the benefits to these beneficiaries, and provides the specific project boundaries as requested.\n",
      "\n",
      "Section F: Recovery Rationale\n",
      "The project addresses the effects of Hurricane Ida and fosters recovery by replacing the existing lift station with a new station that has self-cleaning decrease clog risk pumps and controls. The new station will be more reliable, have advanced controls, and include a SCADA system for efficient monitoring and control. It will mitigate risks from future storms and improve safety for field personnel.\n",
      "\n",
      "This section meets the requirements as it describes how the project addresses the effects of the covered disasters and fosters recovery.\n",
      "\n",
      "Section G: Description of Acquisition(s) Involved (if any)\n",
      "No land acquisition is necessary as all property is owned by the Parish.\n",
      "\n",
      "This section meets the requirements as it states that no land acquisition is necessary.\n",
      "\n",
      "Section H: Mitigation Plan\n",
      "The project will minimize lift station disruptions, promote long-term resiliency, reduce risks from flooding and future hazardous events, and protect waterways from pollutants or erosion. It will mitigate overall health risks and help expedite the recovery of the economy. The project aligns with locally established plans and policies and includes sustainable practices and mitigation components.\n",
      "\n",
      "This section meets the requirements as it describes the mitigation plan and includes sustainable practices and mitigation components.\n",
      "\n",
      "Section I: FEMA Public Assistance Eligibility\n",
      "No FEMA Public Assistance eligibility is mentioned.\n",
      "\n",
      "This section does not meet the requirements as it does not provide information on FEMA Public Assistance eligibility.\n",
      "\n",
      "Additional Notes:\n",
      "The provided information is sufficient to generate an annotation of the proposal and all sections have been addressed. No requirements have been left untouched.\n"
     ]
    }
   ],
   "source": [
    "result = chain({ \"text\":split_outline, \"input_documents\":split_docs2}, return_only_outputs=True)\n",
    "print(result[\"output_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Explore_RCIP_parallelized.ipynb to script\n",
      "[NbConvertApp] Writing 13689 bytes to Explore_RCIP_parallelized.py\n"
     ]
    }
   ],
   "source": [
    "# convert notebook to pure python script\n",
    "!jupyter nbconvert --to script Explore_RCIP_parallelized.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
